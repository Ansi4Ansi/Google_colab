{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ansi4Ansi/Google_colab/blob/main/ML_B2C_2024_Q2_%7C_HW09_ML_unsupervised.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6FFQbU33qyM"
      },
      "source": [
        "# Homework #07: Unsupervised"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1gl-cPkH3qyQ"
      },
      "source": [
        "<span style=\"color: red; font-size: 14pt\">Deadline: 16.06.2019, 23:59</span>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYA7cnpy3qyR"
      },
      "source": [
        "**Оформление ДЗ**:\n",
        "\n",
        "- Выполненное ДЗ сохраните в файл ``ml_b2c2024q2_<Surname>_<Name>_HW#.ipynb``\n",
        "  \n",
        "  (пример ``ml_b2c2024q2__Dral_Alexey_HW01.ipynb``)\n",
        "- Зарегистрироваться и залогиниться в сервисе [Everest](https://everest.distcomp.org/)\n",
        "- Перейти на страницу приложения: [BDT-grader-ML-B2C](https://everest.distcomp.org/apps/BigDataTeam/BDT-grader-ML-B2C)\n",
        "- Выбрать вкладку Submit Job (если отображается иная).\n",
        "- Выбрать в качестве “Task” значение: ``HW09:unsupervised`` (кодовое название для преподвателей: ``ml.unsupervised``)\n",
        "- Загрузить в качестве “Task solution” файл с решением\n",
        "- В качестве Access Token указать тот, который был выслан по почте или в телеграм от аккаунта @bdt_manager\n",
        "\n",
        "**Дополнительные ссылки**\n",
        "- Настройка локального окружения: https://github.com/big-data-team/ml-course\n",
        "- Датасеты UCI: https://archive.ics.uci.edu/\n",
        "\n",
        "**Вопросы**:\n",
        "- Свои вопросы присылайте в Телеграм.\n",
        "\n",
        "**Фидбек**:\n",
        "- Пожалуйста, оставьте свой отзыв после выполнения домашнего задания по сссылке:\n",
        "\n",
        "    https://forms.gle/Pny6dhdmhZZRNNQs5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzX9RE983qyS"
      },
      "source": [
        "### Вопросы на понимание"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPQ7CYsR3qyT"
      },
      "source": [
        "1. Можно ли использовать категориальные признаки для алгоритма K-Means? Если можно, то как? Если нет, то почему?\n",
        "2. В чем разница между K-Means и K-Medoids?\n",
        "3. Кто лучше справится с данными с шумом: K-Means или DBSCAN?\n",
        "4. При каком объеме выборки становится невозможно найти глобальный оптимальный алгоритмов кластеризации? Приведите расчеты / оценки.\n",
        "5. Какую величину выражают собственные значения ковариационной матрицы X.T?\n",
        "6. Что такое Proportion of Variance Explained?\n",
        "7. PCA и SVD это одно и тоже или разные вещи?\n",
        "8. Какая оптимизационная задача решается в t-SNE?\n",
        "9. Какие алгоритмы из PCA, t-SNE являются детерминированными, а какие нет."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdjlzhaT3qyT"
      },
      "source": [
        "<ваши ответы - здесь>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmB_aiPT3qyU"
      },
      "source": [
        "## Полезные import'ы"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EkAy4Izj3qyU"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "print(sys.version)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nzWGaZ8Y3qyV"
      },
      "outputs": [],
      "source": [
        "import sklearn\n",
        "print(sklearn.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zfvmo7XR3qyV"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WdbBkCg13qyV"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition  import PCA\n",
        "from sklearn.datasets import load_digits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rxbHZjSN3qyW"
      },
      "source": [
        "# 1. Data Compression (30 %)\n",
        "\n",
        "PCA can also be used for data compression. We are going to experiment with amount of principal components necessary to recover original image with high quality."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IDQBurPK3qyW"
      },
      "outputs": [],
      "source": [
        "digits = load_digits()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aUzljXQW3qyW"
      },
      "outputs": [],
      "source": [
        "X = digits.data\n",
        "Y = digits.target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gLkwqHI63qyW"
      },
      "outputs": [],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4gMSOpB33qyW"
      },
      "outputs": [],
      "source": [
        "target_image_id = 15\n",
        "\n",
        "plt.figure(figsize=(4,2))\n",
        "plt.imshow(X[target_image_id].reshape((8, 8)), cmap='binary')\n",
        "plt.xticks([])\n",
        "plt.yticks([])\n",
        "plt.title('Source image')\n",
        "\n",
        "fig, axes = plt.subplots(8, 8, figsize=(10, 10))\n",
        "fig.subplots_adjust(hspace=0.1, wspace=0.1)\n",
        "\n",
        "for index, ax in enumerate(axes.flat):\n",
        "    n_components = index + 1\n",
        "    # Task: train PCA transformer with n_components and get reduced\n",
        "    # image with id `target_image_id` plotted in high-dimensional\n",
        "    # feature space\n",
        "    # hint: take special care about shape of observations\n",
        "\n",
        "    <your code>\n",
        "    recovered_image = <your code>\n",
        "\n",
        "    ax.imshow(recovered_image.reshape((8, 8)), cmap='binary')\n",
        "    ax.text(0.95, 0.05, 'n = {0}'.format(n_components), ha='right',\n",
        "            transform=ax.transAxes, color='red')\n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks([])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XIr4T5H33qyW"
      },
      "source": [
        "### How many PCA components do you need to decompress image with quite a good quality?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uGsU1ky_3qyW"
      },
      "outputs": [],
      "source": [
        "# your answer here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TfVTpug53qyW"
      },
      "source": [
        "### How many components do you need to explain 90% of variance?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ukGZyNcb3qyX"
      },
      "outputs": [],
      "source": [
        "# train PCA transformer and get the amount of components from the transformer\n",
        "# <your code>\n",
        "pca_pve90_n_components = <save the found amount components into this variable>\n",
        "print(f\"We need {pca_pve90_n_components} components to explain 90% of variance\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dH5RgcSL3qyX"
      },
      "source": [
        "### Plot Total explained variance to support your statement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pLvZnBg33qyX"
      },
      "outputs": [],
      "source": [
        "pca = PCA().fit(X)\n",
        "\n",
        "plt.figure(figsize=(10,7))\n",
        "# plot cumulative PVE for each value of [1..n_components]\n",
        "# hint: see np.cumsum\n",
        "plt.plot(<your code>, color='black', lw=2)\n",
        "\n",
        "# plot horizontal line for PVE 90%, set \"red\" color\n",
        "plt.<your code>\n",
        "# plot vertical line for chosen pca_pve90_n_components, set \"blue\" color\n",
        "plt.<your code, use `pca_pve90_n_components` variable>\n",
        "\n",
        "\n",
        "plt.xlim(0, X.shape[1])\n",
        "plt.yticks(np.arange(0, 1.1, 0.1))\n",
        "plt.xlabel('Number of components')\n",
        "plt.ylabel('Total explained variance');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AIoX4ttT3qyX"
      },
      "source": [
        "# 2. Labeled Faces in the Wild (LFW) (30%)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9GSdEv63qyX"
      },
      "source": [
        "### Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8svrorDO3qyX"
      },
      "outputs": [],
      "source": [
        "import PIL\n",
        "print(PIL.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cu-jjRnq3qyX"
      },
      "outputs": [],
      "source": [
        "from sklearn import datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xX9RLCuk3qyX"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "lfw_people = datasets.fetch_lfw_people(\n",
        "    min_faces_per_person=50,\n",
        "    resize=0.4,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ATOfXZIN3qyX"
      },
      "outputs": [],
      "source": [
        "print(\n",
        "    f'{lfw_people.data.shape[0]} objects, '\n",
        "    + f'{lfw_people.data.shape[1]} features, '\n",
        "    + f'{len(lfw_people.target_names)} classes'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jw8v7lNJ3qyX"
      },
      "outputs": [],
      "source": [
        "# Show label distribution\n",
        "for person_index, name in enumerate(lfw_people.target_names):\n",
        "    print(f\"{name:20}: {(lfw_people.target == person_index).sum():3} photos.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ke7jSV5B3qyX"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(8, 6))\n",
        "\n",
        "for subplot_index in range(15):\n",
        "    ax = fig.add_subplot(3, 5, subplot_index + 1, xticks=[], yticks=[])\n",
        "    ax.imshow(lfw_people.images[subplot_index], cmap='bone')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "inq-itpf3qyX"
      },
      "outputs": [],
      "source": [
        "# split dataset into train and test in ratio 75:25\n",
        "X_train, X_test, y_train, y_test = <your code>\n",
        "\n",
        "print('Train size:', X_train.shape[0], 'Test size:', X_test.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9-eg8cW73qyY"
      },
      "outputs": [],
      "source": [
        "# Train PCA on \"train\" dataset with 100 components\n",
        "<your code>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PuDfKoNk3qyY"
      },
      "outputs": [],
      "source": [
        "# Print how many PVE explained by all 100 n_components\n",
        "<your code>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DrW7o2eo3qyY"
      },
      "outputs": [],
      "source": [
        "# Plot \"Total explained variance\" over n_components in range [0,100]\n",
        "plt.figure(figsize=(10,7))\n",
        "<your code>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "250lTa0J3qyY"
      },
      "outputs": [],
      "source": [
        "# Plot the first 30 Principal Components in the original feature space\n",
        "# note: use grid 3 (rows) x 10 (columns)\n",
        "# note: consider face shape 50x37\n",
        "fig = plt.figure(figsize=(16, 6))\n",
        "<your code>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BzgdaZbv3qyY"
      },
      "source": [
        "### What can you say about principle components? Does any of the principal components help to find feature dimension such as \"nose\", \"lightning\" or something else?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cgwtEqCV3qyY"
      },
      "outputs": [],
      "source": [
        "# your answer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCYdwyFy3qyY"
      },
      "source": [
        "### Make some fun"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BoO2O4eA3qyY"
      },
      "outputs": [],
      "source": [
        "# What is the average face in the \"wild\"?\n",
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jDQ5rFO_3qyc"
      },
      "outputs": [],
      "source": [
        "# Average all features with np.mean\n",
        "plt.imshow(X_train.mean(axis=0).reshape(50, 37), cmap='bone')\n",
        "plt.xticks([])\n",
        "plt.yticks([]);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wEPcz9lu3qyc"
      },
      "outputs": [],
      "source": [
        "# Occasionally PCA does it for you already\n",
        "plt.imshow(pca.mean_.reshape((50, 37)), cmap='bone')\n",
        "plt.xticks([])\n",
        "plt.yticks([]);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7aDGA5f3qyc"
      },
      "source": [
        "# 3. Pipeline optimization (40%)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LD5kiqhd3qyd"
      },
      "outputs": [],
      "source": [
        "# Our goal is to speed-up calculations without loosing much of a quality with the\n",
        "# help of dimensionality reduction algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wg_yQvxC3qyd"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.svm import LinearSVC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kOIKyZo13qyd"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "# Train LinearSVC on X_train, y_train with cv=5, set number of iteration to 10^4\n",
        "cv_score = cross_val_score(<your code>)\n",
        "print(f\"{cv_score.mean():.3f}, {cv_score.std():.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Sl3eAkn3qyd"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "# you should see warnings \"Liblinear failed to converge, increase the number of iterations\"\n",
        "# instead of doing this, let us add scaling to the pipeline, it helps optimization algorithms\n",
        "\n",
        "pipeline = Pipeline(<your code>)\n",
        "cv_score = cross_val_score(<your code>)\n",
        "print(f\"{cv_score.mean():.3f}, {cv_score.std():.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wbyib32O3qyd"
      },
      "outputs": [],
      "source": [
        "# now you should be able to get better quality and to get rid of the warning\n",
        "# to save time necessary to train the model\n",
        "# copy time from the previous cell and cast to seconds\n",
        "wall_time_in_seconds = <wall time from the previous cell execution>\n",
        "original_SVM_quality = cv_score.mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VvEf_xw53qyd"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "# our goal is to speed-up calculations by 100x without significant decrease in quality (let's say 1-2%)\n",
        "# I heard that PCA might be of a great help\n",
        "# add the first step (PCA with n_components = 10) to our pipeline:\n",
        "\n",
        "pipeline = Pipeline(<your code>)\n",
        "cv_score = cross_val_score(<your code>)\n",
        "print(f\"{cv_score.mean():.3f}, {cv_score.std():.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HrceV0m73qyd"
      },
      "outputs": [],
      "source": [
        "# Wow, do you see how fast is it?\n",
        "# Let us try to find the appropriate amount of components\n",
        "# with the help of GridSearchCV\n",
        "pipeline = Pipeline(<your code>)\n",
        "\n",
        "param_grid = {\n",
        "    'pca__n_components': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 200, 300, 400, 500],\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(\n",
        "    pipeline, param_grid, iid=False, cv=5,\n",
        "    return_train_score=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nrNZSW9V3qyd"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "# Let's grid_search do all the magic for us:\n",
        "grid_search.<your magic code>\n",
        "print(f\"Best parameter (CV score={grid_search.best_score_:0.3f}): {grid_search.best_params_}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmFVxgoN3qyd"
      },
      "source": [
        "### Analyse and visualize results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9FinEIPU3qyd"
      },
      "outputs": [],
      "source": [
        "# show CV-results\n",
        "cv_results_df = pd.DataFrame(grid_search.cv_results_)\n",
        "cv_results_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K34442FW3qyd"
      },
      "source": [
        "#### Visualize the best quality pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AfMChwyn3qye"
      },
      "outputs": [],
      "source": [
        "pca = PCA().fit(X_train)\n",
        "\n",
        "fig, (ax0, ax1) = plt.subplots(nrows=2, sharex=True, figsize=(6, 6))\n",
        "ax0.plot(pca.explained_variance_ratio_, linewidth=2)\n",
        "ax0.set_ylabel('PCA explained variance')\n",
        "ax0.axvline(\n",
        "    grid_search.best_estimator_.named_steps['pca'].n_components,\n",
        "    linestyle=':', label='n_components chosen'\n",
        ")\n",
        "ax0.legend(prop=dict(size=12))\n",
        "\n",
        "cv_results_df.plot(\n",
        "    x='param_pca__n_components', y='mean_test_score', yerr='std_test_score',\n",
        "    legend=True, ax=ax1\n",
        ")\n",
        "ax1.axvline(\n",
        "    grid_search.best_estimator_.named_steps['pca'].n_components,\n",
        "    linestyle=':', label='n_components chosen'\n",
        ")\n",
        "ax1.set_ylabel('Classification accuracy (CV=5)')\n",
        "ax1.set_xlabel('n_components')\n",
        "ax1.set_xlim(left=0)\n",
        "\n",
        "plt.tight_layout();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QxwnYblW3qye"
      },
      "outputs": [],
      "source": [
        "# plot \"time\" spent to fit the models\n",
        "cv_results_df.plot(\n",
        "    x='param_pca__n_components', y='mean_fit_time',\n",
        "    legend=True\n",
        ")\n",
        "plt.title(\"Fit time in seconds\");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nE38yNTb3qye"
      },
      "outputs": [],
      "source": [
        "# Compared to the original `wall_time_in_seconds` what is speed-up factor?\n",
        "# Compared to the original `original_SVM_quality` what is the quality of best-pipeline?\n",
        "# Which model are you going to use in production?\n",
        "# How much of the variance explained was enough to achieve such a good quality?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cvNKX6Ie3qye"
      },
      "outputs": [],
      "source": [
        "<your answer>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NY-q7jol3qye"
      },
      "source": [
        "### Validate quality of the best model on hold-out dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZVpaOaIc3qye"
      },
      "outputs": [],
      "source": [
        "y_pred = grid_search.best_estimator_.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6q1J6hLQ3qye"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
        "\n",
        "print(\"Accuracy: %f\" % accuracy_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred, target_names=lfw_people.target_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IDGU-kki3qye"
      },
      "outputs": [],
      "source": [
        "M = confusion_matrix(y_test, y_pred)\n",
        "# normalize confusion matrix over y_test rows\n",
        "M_normalized = M.astype('float') / M.sum(axis=1)[:, np.newaxis]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dUr_tol03qye"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "im = plt.imshow(M_normalized, cmap='Greens')\n",
        "plt.colorbar(im, shrink=0.7)\n",
        "tick_marks = np.arange(len(lfw_people.target_names))\n",
        "plt.xticks(tick_marks - 0.5, lfw_people.target_names, rotation=45)\n",
        "plt.yticks(tick_marks, lfw_people.target_names)\n",
        "plt.tight_layout()\n",
        "plt.xlabel('Predicted person')\n",
        "plt.ylabel('True person')\n",
        "plt.title('Normalized confusion matrix');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFgVkq8X3qyf"
      },
      "source": [
        "### Q&A:\n",
        "1. Which person was easy to classify?\n",
        "2. Which person was difficult to classify?\n",
        "3. What is the most common error? Which person was frequenlty misclassified by another one?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yYdjehI-3qyf"
      },
      "outputs": [],
      "source": [
        "# your answer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EpjS1WTS3qyf"
      },
      "source": [
        "## Bonus"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cgAb6lI73qyf"
      },
      "source": [
        "According to the article \"Pinto, Nicolas, James J. DiCarlo, and David D. Cox. \"How far can you get with a modern face recognition test set using only simple features?.\" 2009 IEEE Conference on Computer Vision and Pattern Recognition. IEEE, 2009.\" http://www.coxlab.org/pdfs/pinto-dicarlo-cox-cvpr-2009-mkl.pdf\n",
        "    \n",
        "they were able to get the quality 79.35%. Can you do better?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W0-yC6yQ3qyf"
      },
      "outputs": [],
      "source": [
        "<your code and comments>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37AmlAvY3qyf"
      },
      "source": [
        "## Useful links\n",
        "- [Eigenface](https://en.wikipedia.org/wiki/Eigenface)\n",
        "- [sklearn.decomposition](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.decomposition)\n",
        "- [LIBLinear home page](https://www.csie.ntu.edu.tw/~cjlin/liblinear/)\n",
        "- [LIBLinear FAQ](https://www.csie.ntu.edu.tw/~cjlin/liblinear/FAQ.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0C-ZEok33qyf"
      },
      "source": [
        "Надеемся, было интересно и полезно.\n",
        "\n",
        "Пожалуйста, оставьте обратную связь по этому домашнему заданию: https://forms.gle/Pny6dhdmhZZRNNQs5."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "name": "lesson8_part2_PCA.ipynb",
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}